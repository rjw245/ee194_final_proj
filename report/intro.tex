\section{Introduction}\label{sec::introduction}

As the "power wall" has stalled advances in clock frequency, the industry has begun to favor parallel architectures to improve performance~\cite{sutter2005free}. This shift has significant ramifications for
programmers. A programâ€™s performance scales trivially with clock frequency, whereas parallel programs
often require significant design effort on the part of the programmer to scale well. But if software performance is to improve in step with hardware, concurrent software must become the norm. It is difficult for most programmers to decompose an algorithm into parallel workloads and to anticipate all of the interactions that
can occur. This proliferates new kinds of errors that are much harder to anticipate, find, and prevent including deadlock, livelock, and data races. Much work has been done analyzing the nature of, locating, and reproducing these common programmer errors~\cite{kendo,grace,ctrigger,heisenbug,learning}. Many common concurrency challenges, however, have not conclusively been solved for programmers.

It is important that programmers start writing parallel programs in order to scale software performance with hardware. To this end, programmers should feel confident in their ability to write safe, parallel code. The question becomes: Which tools currently available are best suited for the task? One technique that has had moderate success is the development of thread-safe programming languages to help programmers better express their intentions and avoid common mistakes~\cite{learning}.

The goal of this paper is to analyze one such language, Rust, a new systems programming language that aims to help programmers write concurrent code with zero-cost abstractions~\cite{rust-lang}. Designed to be a modern, open-source systems programming language, Rust leverages a powerful type system to make static guarantees about program safety. Rust allows for manual memory management similar to C, but it employs several special rules at compile time regarding variable bindings and memory allocation. One rule that Rust enforces is the concept of \textit{ownership} to ensure memory safety. When a variable binding is assigned, such as \texttt{let x = y}, the ownership of the data referenced by \texttt{y} is transferred to \texttt{x}. Any subsequent usages of \texttt{y} are invalid. In this way, Rust enforces a one-to-one binding between symbols and data. Ownership is also transferred when passing data to functions. Data can be borrowed, meaning it is not deallocated when its binding goes out of scope, but the programmer must make this explicit. Data can be borrowed as mutable or immutable, also specified explicitly, and the compiler makes sure that permissions to borrowed data are not violated by the borrower. Furthermore, the Rust compiler enforces the notion of \textit{lifetimes}, which ensures when a binding falls out of scope, the reference is deleted from the stack and its data is de-allocated from the heap. This means that dangling pointers are no longer a danger to programmers. With ownership, borrowing, and lifetimes, Rust forces the programmer to make promises about how they will share and mutate data which are checked at compile time. These constraints have serious implications for concurrent programming, as we discuss in Section~\ref{sec::rust_concurrency}. We are interested in assessing whether or not they impact the performance of concurrency in Rust.

For comparison, we have selected the C programming language and the Pthreads API. We chose C as it is a natural competitor to Rust, and its (lack of) safety features and threading paradigms are well known. Further, many parallel programming errors specifically caught by the Rust type system are made often in C.
The remainder of this paper explores the tradeoffs made by the Rust programming language in terms of usability and performance with respect to C implementations using Pthreads. Section~\ref{sec::relatedwork} summarizes related projects which address concurrent programming challenge, Section~\ref{sec::methodology} discusses our experimental methodology, Section~\ref{sec::results} describes our findings, and Section~\ref{sec::conclusion} concludes.
